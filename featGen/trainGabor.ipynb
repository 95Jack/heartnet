{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "import arff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.svm import NuSVC, SVC\n",
    "from sklearn.svm import libsvm\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FBANK_feat = os.path.join('FBANK','binnedFeat.mat')\n",
    "FBANK_label = os.path.join('FBANK','binnedLabels.csv')\n",
    "ComParE_feat = os.path.join('baseline','openSMILEall_PCG.mat')\n",
    "BOAW_feat = os.path.join('baseline_boaw','feat','boawFeat.4096.arff')\n",
    "BOAW_meta = os.path.join('baseline_boaw','feat','BOAW_filenames.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def severe2abnormal(labels):\n",
    "    for idx,each in enumerate(labels):\n",
    "        if each == 2:\n",
    "            labels[idx]=1\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/media/taufiq/Data1/heart_sound/heartnet/featGen/mfcc.csv',header=None, delimiter=';')\n",
    "# df.head()\n",
    "# with open('/media/taufiq/Data1/heart_sound/heartnet/featGen/BOAW_filenames.txt','w') as fp:\n",
    "#     for each in df[0].drop_duplicates().values:\n",
    "#         fp.write(\"%s\\n\" % each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load_BOAW:\n",
    "\n",
    "df = arff.load(open(BOAW_feat,'r'))\n",
    "boawData = pd.DataFrame(np.array(df['data'],dtype=float))\n",
    "del df\n",
    "\n",
    "boawFilenames = []\n",
    "with open(BOAW_meta, 'r') as fp:\n",
    "    line = fp.readline()\n",
    "    boawFilenames.append(line.split('\\n')[0])\n",
    "    while line:\n",
    "            line = fp.readline()\n",
    "            boawFilenames.append(line.split('\\n')[0])\n",
    "boawFilenames = boawFilenames[:-1]\n",
    "boawData['filenames'] = boawFilenames\n",
    "boawData.rename({len(boawData.columns)-2:'label'},axis='columns',inplace=True)\n",
    "boawData.label = [int(each) for each in boawData.label]\n",
    "boawData['dataset'] = [each[-1][0] for each in boawData.filenames.str.split('_')]\n",
    "boawData.set_index('filenames',drop=True,inplace=True)\n",
    "\n",
    "del boawFilenames\n",
    "boawData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load BoaW fixed\n",
    "\n",
    "foldnum = 1\n",
    "codebook = 4096\n",
    "feat_path = os.path.join('baseline_boaw/feat/')\n",
    "meta_path = os.path.join('..','..','feature','mfcc')\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "filenames = []\n",
    "\n",
    "for subset in ['train','dev']:\n",
    "    BOAW_feat = os.path.join(feat_path,\n",
    "                             'fold%d.%s.%d.arff' % (foldnum,subset,codebook))\n",
    "    BOAW_meta = os.path.join(meta_path,'fold%d.%s.filenames.txt' % (foldnum,subset))\n",
    "    print(BOAW_feat)\n",
    "    print(os.path.isfile(BOAW_meta))\n",
    "    \n",
    "    df = arff.load(open(BOAW_feat,'r'))\n",
    "    boawData = pd.DataFrame(np.array(df['data'],dtype=float))\n",
    "    del df\n",
    "\n",
    "    boawFilenames = []\n",
    "    with open(BOAW_meta, 'r') as fp:\n",
    "        line = fp.readline()\n",
    "        boawFilenames.append(line.split('\\n')[0])\n",
    "        while line:\n",
    "                line = fp.readline()\n",
    "                boawFilenames.append(line.split('\\n')[0])\n",
    "    boawFilenames = boawFilenames[:-1]\n",
    "    boawData['filenames'] = boawFilenames\n",
    "    boawData.rename({len(boawData.columns)-2:'label'},axis='columns',inplace=True)\n",
    "    boawData.label = [int(each) for each in boawData.label]\n",
    "    boawData['dataset'] = [each[-1][0] for each in boawData.filenames.str.split('_')]\n",
    "    boawData.set_index('filenames',drop=True,inplace=True)\n",
    "    \n",
    "    filenames.append(boawFilenames)\n",
    "    del boawFilenames\n",
    "    \n",
    "    X.append(boawData[range(4096)].values)\n",
    "    y.append(boawData.label.values)\n",
    "    \n",
    "    del boawData\n",
    "    \n",
    "X = np.vstack(X)\n",
    "y = np.hstack(y)\n",
    "filenames = np.hstack(filenames)\n",
    "\n",
    "boawData = pd.DataFrame(X)\n",
    "boawData['filenames'] = filenames\n",
    "boawData['label'] = y\n",
    "boawData.set_index('filenames',drop=True,inplace=True)\n",
    "boawData['dataset'] = [each[-1][0] for each in boawData.index.str.split('_')]\n",
    "boawData.head()\n",
    "\n",
    "del X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load FBANK: \n",
    "\n",
    "df = loadmat(FBANK_feat)\n",
    "fbankData = pd.DataFrame(df['feats'])\n",
    "fbankMeta = pd.read_csv(FBANK_label)\n",
    "fbankMeta.file_name = [each[0] for each in fbankMeta.file_name.str.split('.')]\n",
    "fbankData = fbankData.join(fbankMeta)\n",
    "fbankData.dropna(inplace=True)\n",
    "fbankData.rename({'file_name':'filenames'},axis=\"columns\",inplace=True)\n",
    "fbankData.label = [int(each) for each in fbankData.label]\n",
    "fbankData['dataset'] = [each[-1][0] for each in fbankData.filenames.str.split('_')]\n",
    "fbankData.set_index('filenames',drop=True,inplace=True)\n",
    "\n",
    "del df, fbankMeta\n",
    "\n",
    "fbankData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Load ComParE:\n",
    "\n",
    "df = loadmat(ComParE_feat)\n",
    "\n",
    "compareData = pd.DataFrame(df['dataTrain'])\n",
    "compareData = pd.concat((compareData,pd.DataFrame(df['dataDev'])),axis=\"rows\").reset_index(drop=True)\n",
    "compareData['label'] = np.concatenate((np.hstack(df['TrainLabels']),np.hstack(df['DevLabels'])),axis=0)\n",
    "compareData['filenames'] = np.concatenate((np.hstack(df['TrainFiles']),np.hstack(df['DevFiles'])),axis=0)\n",
    "compareData.filenames = [each[0] for each in compareData.filenames.str.split('.')]\n",
    "compareData.label = [int(each) for each in compareData.label]\n",
    "compareData['dataset'] = [each[-1][0] for each in compareData.filenames.str.split('_')]\n",
    "compareData.set_index('filenames',drop=True,inplace=True)\n",
    "\n",
    "del df\n",
    "\n",
    "compareData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fuse dataframes\n",
    "\n",
    "print(\"Target Size %d\" % (len(boawData.columns)-2+len(fbankData.columns)-2+len(compareData.columns)))\n",
    "fused = boawData[range(len(boawData.columns)-2)].join(fbankData[range(len(fbankData.columns)-2)],rsuffix='fbank')\n",
    "fused = fused.join(compareData,lsuffix='fused')\n",
    "fused.dropna()\n",
    "fused.columns = range(len(fused.columns))\n",
    "fused.rename({len(fused.columns)-2:'label',len(fused.columns)-1:'dataset'},axis=\"columns\",inplace=True)\n",
    "\n",
    "# del boawData, fbankData, compareData\n",
    "\n",
    "fused.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Under-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = '0'\n",
    "\n",
    "np.random.seed(1)\n",
    "rand_states = np.random.randint(20000,size=(10,))\n",
    "scaler = StandardScaler()\n",
    "mask = compareData.dataset == dataset\n",
    "X_ = scaler.fit_transform(compareData[range(6373)][mask]) ## .4489999\n",
    "results = []\n",
    "for rand_state in rand_states:\n",
    "    rand_state = 144\n",
    "    rus = RandomUnderSampler(random_state=rand_state)    \n",
    "    X,y = rus.fit_resample(X_,compareData.label[mask])\n",
    "    \n",
    "    clf = NuSVC(kernel='linear',probability=True,verbose=True,\n",
    "              random_state=rand_state, nu = .3)\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y,\n",
    "                                                      test_size = 0.2,\n",
    "                                                      random_state = rand_state,\n",
    "                                                      shuffle = True)\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    results.append(accuracy_score(clf.predict(X_val), y_val))\n",
    "print(np.mean(results))\n",
    "print(np.std(results))\n",
    "\n",
    "sns.distplot(results,20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip(rand_states,results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_grid = [0.0001 0.001, 0.01, 0.1, 1, 10]\n",
    "# gamma_grid = [0.001, 0.01, 0.1, 1, 10]\n",
    "param_grid = {'C': C_grid}\n",
    "\n",
    "grid = GridSearchCV(fbankBbc, param_grid, cv = 4, scoring = \"accuracy\")\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(grid.best_score_)\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = '0'\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "mask = compareData.dataset == dataset\n",
    "X = scaler.fit_transform(compareData[range(6373)][mask]) ## .4489999\n",
    "y = compareData.label[mask]\n",
    "\n",
    "clf = NuSVC(kernel='linear',probability=True,verbose=False,\n",
    "          random_state=144,\n",
    "            nu = .5)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y,\n",
    "                                                  test_size = 0.3,\n",
    "                                                  random_state = 114,\n",
    "                                                  shuffle = True)\n",
    "bbc = BalancedBaggingClassifier(base_estimator=clf,\n",
    "                                n_estimators=100,\n",
    "                                oob_score = True,\n",
    "                                random_state=114,\n",
    "                               )\n",
    "bbc.fit(X_train,y_train)\n",
    "print(\"Out of Bag Score &f\" % bbc.oob_score_)\n",
    "print(\"Validation split accuracy &f\" % accuracy_score(bbc.predict(X_val), y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuse Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_state = 114\n",
    "n_estimators = 10\n",
    "dataset = '0'\n",
    "\n",
    "scaler = StandardScaler()\n",
    "mask = fused.dataset == dataset\n",
    "\n",
    "X = scaler.fit_transform(fused[range(len(fused.columns)-2)][mask]) ## .4489999\n",
    "y = fused.label[mask]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y,\n",
    "                                                  test_size = 0.3,\n",
    "                                                  random_state = rand_state,\n",
    "                                                  shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev set of Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_state = 1\n",
    "dataset = '0'\n",
    "\n",
    "scaler = StandardScaler()\n",
    "mask1 = fused.dataset == dataset\n",
    "mask2 = fused[mask1].index.str.contains('train')\n",
    "mask3 = fused[mask1].index.str.contains('devel')\n",
    "\n",
    "X = scaler.fit_transform(fused[range(len(fused.columns)-2)][mask1]) ## .4489999\n",
    "y = fused.label[mask1]\n",
    "\n",
    "X_train = X[mask2]\n",
    "y_train = y[mask2]\n",
    "X_val = X[mask3]\n",
    "y_val = y[mask3]\n",
    "\n",
    "del mask1, mask2, mask3, X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fold1_noFIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_state = 1\n",
    "n_estimators = 5\n",
    "scaler = StandardScaler()\n",
    "\n",
    "fold1_val = '/media/taufiq/Data1/heart_sound/feature/segmented_noFIR/validation1.txt'\n",
    "df = pd.read_csv(fold1_val,header=None)\n",
    "df[0] = ['train_'+each for each in df[0]]\n",
    "df.columns = ['filenames']\n",
    "df.set_index('filenames',drop=True,inplace=True)\n",
    "mask = fused.dataset == '0'\n",
    "fold1_data = fused[~mask]\n",
    "\n",
    "mask1 = [each in df.index.values for each in fold1_data.index.values]\n",
    "mask2 = [not each for each in mask1]\n",
    "X = fold1_data[range(len(fold1_data.columns)-2)]\n",
    "y = fold1_data.label\n",
    "del fold1_data\n",
    "\n",
    "# X_train = scaler.fit_transform(X[mask2])\n",
    "X_train = np.asarray(X[mask2].values)\n",
    "y_train = y[mask2]\n",
    "# X_val = scaler.transform(X[mask1])\n",
    "X_val = np.asarray(X[mask1].values)\n",
    "y_val = y[mask1]\n",
    "\n",
    "del mask, mask1, mask2, X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fold2_noFIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_state = 1\n",
    "n_estimators = 5\n",
    "\n",
    "fold1_val = '/media/taufiq/Data1/heart_sound/feature/segmented_noFIR/validation2.txt'\n",
    "df = pd.read_csv(fold1_val,header=None)\n",
    "df[0] = ['train_'+each for each in df[0]]\n",
    "df.columns = ['filenames']\n",
    "df.set_index('filenames',drop=True,inplace=True)\n",
    "mask = fused.dataset == '0'\n",
    "fold1_data = fused[~mask]\n",
    "\n",
    "mask1 = [each in df.index.values for each in fold1_data.index.values]\n",
    "mask2 = [not each for each in mask1]\n",
    "X = scaler.fit_transform(fold1_data[range(len(fold1_data.columns)-2)])\n",
    "y = fold1_data.label\n",
    "del fold1_data\n",
    "\n",
    "X_train = X[mask2]\n",
    "y_train = y[mask2]\n",
    "X_val = X[mask1]\n",
    "y_val = y[mask1]\n",
    "\n",
    "del mask, mask1, mask2, X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fold3_noFIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_state = 1\n",
    "n_estimators = 5\n",
    "\n",
    "fold1_val = '/media/taufiq/Data1/heart_sound/feature/segmented_noFIR/validation3.txt'\n",
    "df = pd.read_csv(fold1_val,header=None)\n",
    "df[0] = ['train_'+each for each in df[0]]\n",
    "df.columns = ['filenames']\n",
    "df.set_index('filenames',drop=True,inplace=True)\n",
    "mask = fused.dataset == '0'\n",
    "fold1_data = fused[~mask]\n",
    "\n",
    "mask1 = [each in df.index.values for each in fold1_data.index.values]\n",
    "mask2 = [not each for each in mask1]\n",
    "X = scaler.fit_transform(fold1_data[range(len(fold1_data.columns)-2)])\n",
    "y = fold1_data.label\n",
    "del fold1_data\n",
    "\n",
    "X_train = X[mask2]\n",
    "y_train = y[mask2]\n",
    "X_val = X[mask1]\n",
    "y_val = y[mask1]\n",
    "\n",
    "del mask, mask1, mask2, X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fold0_noFIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_state = 1\n",
    "n_estimators = 5\n",
    "\n",
    "fold1_val = '/media/taufiq/Data1/heart_sound/feature/segmented_noFIR/validation0.txt'\n",
    "df = pd.read_csv(fold1_val,header=None)\n",
    "df[0] = ['train_'+each for each in df[0]]\n",
    "df.columns = ['filenames']\n",
    "df.set_index('filenames',drop=True,inplace=True)\n",
    "mask = fused.dataset == '0'\n",
    "fold1_data = fused[~mask]\n",
    "\n",
    "mask1 = [each in df.index.values for each in fold1_data.index.values]\n",
    "mask2 = [not each for each in mask1]\n",
    "X = scaler.fit_transform(fold1_data[range(len(fold1_data.columns)-2)])\n",
    "y = fold1_data.label\n",
    "del fold1_data\n",
    "\n",
    "X_train = X[mask2]\n",
    "y_train = y[mask2]\n",
    "X_val = X[mask1]\n",
    "y_val = y[mask1]\n",
    "\n",
    "del mask, mask1, mask2, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verboseMetrics(y_val,softScores,verbose=True):\n",
    "    eps = 1.1e-5\n",
    "    if Counter(y_val).keys()[-1] == 1:\n",
    "        TN, FP, FN, TP = confusion_matrix(y_val, np.argmax(softScores,axis=-1), labels=[0,1]).ravel()\n",
    "        sensitivity = TP / (TP + FN + eps)\n",
    "        specificity = TN / (TN + FP + eps)\n",
    "        precision = TP / (TP + FP + eps)\n",
    "        F1 = 2 * (precision * sensitivity) / (precision + sensitivity + eps)\n",
    "        Macc = (sensitivity + specificity) / 2\n",
    "        if verbose:\n",
    "            print(\"TN:{},FP:{},FN:{},TP:{},Sensitivity:{},Specificity{},Macc:{},F1:{}\".format(TN, FP, FN, TP,sensitivity,specificity,Macc,F1))\n",
    "        return Macc\n",
    "    elif Counter(y_val).keys()[-1] == 2:\n",
    "        logs = dict()\n",
    "        confmat = confusion_matrix(y_pred=np.argmax(softScores,axis=-1), y_true=y_val)\n",
    "        logs['recall0'] = confmat[0, 0] / np.sum(confmat[0, :])\n",
    "        logs['recall1'] = confmat[1, 1] / np.sum(confmat[1, :])\n",
    "        logs['recall2'] = confmat[2, 2] / np.sum(confmat[2, :])\n",
    "        logs['UAR'] = np.mean([logs['recall0'], logs['recall1'], logs['recall2']])\n",
    "        if verbose:\n",
    "            print(logs.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BOAW Train\n",
    "del clf\n",
    "\n",
    "clf = NuSVC(kernel='linear',probability=True,verbose=False,\n",
    "          random_state=rand_state,\n",
    "            nu = .5)\n",
    "\n",
    "boawBbc = BalancedBaggingClassifier(base_estimator=clf,\n",
    "                                n_estimators=n_estimators,\n",
    "                                oob_score = True,\n",
    "                                random_state=rand_state,\n",
    "                                sampling_strategy = 'not minority'\n",
    "                               )\n",
    "boawBbc.fit(X_train[:,:4096],y_train)\n",
    "print(\"Out of Bag Score Boaw %f\" % boawBbc.oob_score_)\n",
    "print(\"Validation split accuracy Boaw %f\" % accuracy_score(y_val,boawBbc.predict(X_val[:,:4096])))\n",
    "verboseMetrics(y_val,boawBbc.predict_proba(X_val[:,:4096]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fbank Train\n",
    "del clf\n",
    "\n",
    "clf = NuSVC(kernel='linear',probability=True,verbose=False,\n",
    "          random_state=rand_state,\n",
    "            nu = .5)\n",
    "\n",
    "fbankBbc = BalancedBaggingClassifier(base_estimator=clf,\n",
    "                                n_estimators=n_estimators,\n",
    "                                oob_score = True,\n",
    "                                random_state=rand_state,\n",
    "                                sampling_strategy = 'not minority'\n",
    "                               )\n",
    "fbankBbc.fit(X_train[:,4096:4096+2707],y_train)\n",
    "print(\"Out of Bag Score Fbank %f\" % fbankBbc.oob_score_)\n",
    "print(\"Validation split accuracy Fbank %f\" % accuracy_score(y_val,fbankBbc.predict(X_val[:,4096:4096+2707])))\n",
    "verboseMetrics(y_val,fbankBbc.predict_proba(X_val[:,4096:4096+2707]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare Train\n",
    "del clf\n",
    "\n",
    "clf = NuSVC(kernel='linear',probability=True,verbose=False,\n",
    "          random_state=rand_state,\n",
    "            nu = .5)\n",
    "\n",
    "compareBbc = BalancedBaggingClassifier(base_estimator=clf,\n",
    "                                n_estimators=n_estimators,\n",
    "                                oob_score = True,\n",
    "                                random_state=rand_state,\n",
    "                                sampling_strategy = 'not minority',\n",
    "                               )\n",
    "compareBbc.fit(X_train[:,4096+2707:],y_train)\n",
    "print(\"Out of Bag Score Compare %f\" % compareBbc.oob_score_)\n",
    "print(\"Validation split accuracy Compare %f\" % accuracy_score(y_val, compareBbc.predict(X_val[:,4096+2707:])))\n",
    "verboseMetrics(y_val,compareBbc.predict_proba(X_val[:,4096+2707:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Weighted fusion posteriors\n",
    "\n",
    "weights = [.92,.055,.025]\n",
    "\n",
    "softScores = boawBbc.predict_proba(X_train[:,:4096])*weights[1]+fbankBbc.predict_proba(X_train[:,4096:4096+2707])*weights[2]+compareBbc.predict_proba(X_train[:,4096+2707:])*weights[0]\n",
    "print(\"Training accuracy Combination %f\" % accuracy_score(y_train, np.argmax(softScores,axis=-1)))\n",
    "verboseMetrics(y_train,softScores)\n",
    "\n",
    "softScores = boawBbc.predict_proba(X_val[:,:4096])*weights[1]+fbankBbc.predict_proba(X_val[:,4096:4096+2707])*weights[2]+compareBbc.predict_proba(X_val[:,4096+2707:])*weights[0]\n",
    "print(\"Validation accuracy Combination %f\" % accuracy_score(y_val, np.argmax(softScores,axis=-1)))\n",
    "verboseMetrics(y_val,softScores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OverSampling with BalancedBaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1 \n",
    "\n",
    "## BOAW Train\n",
    "del clf\n",
    "\n",
    "clf = SVC(kernel='linear',probability=True,verbose=False,\n",
    "          random_state=rand_state,\n",
    "          C = C,\n",
    "           )\n",
    "\n",
    "boawBbc = BalancedBaggingClassifier(base_estimator=clf,\n",
    "                                n_estimators=n_estimators,\n",
    "                                oob_score = True,\n",
    "                                random_state=rand_state,\n",
    "                                sampling_strategy = 'not majority'\n",
    "                               )\n",
    "boawBbc.fit(X_train[:,:4096],y_train)\n",
    "# print(\"Out of Bag Score Boaw %f\" % boawBbc.oob_score_)\n",
    "# print(\"Validation split accuracy Boaw %f\" % accuracy_score(y_val,boawBbc.predict(X_val[:,:4096])))\n",
    "verboseMetrics(y_val,boawBbc.predict_proba(X_val[:,:4096]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fbank Train\n",
    "del clf\n",
    "\n",
    "clf = SVC(kernel='linear',probability=True,verbose=False,\n",
    "          random_state=rand_state,\n",
    "            C = C,\n",
    "         )\n",
    "\n",
    "fbankBbc = BalancedBaggingClassifier(base_estimator=clf,\n",
    "                                n_estimators=n_estimators,\n",
    "                                oob_score = True,\n",
    "                                random_state=rand_state,\n",
    "                                sampling_strategy = 'not majority'\n",
    "                               )\n",
    "fbankBbc.fit(X_train[:,4096:4096+2707],y_train)\n",
    "# print(\"Out of Bag Score Fbank %f\" % fbankBbc.oob_score_)\n",
    "# print(\"Validation split accuracy Fbank %f\" % accuracy_score(y_val,fbankBbc.predict(X_val[:,4096:4096+2707])))\n",
    "verboseMetrics(y_val,fbankBbc.predict_proba(X_val[:,4096:4096+2707]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare Train\n",
    "del clf\n",
    "\n",
    "clf = SVC(kernel='linear',probability=True,verbose=False,\n",
    "          random_state=rand_state,\n",
    "          C = C,\n",
    "         )\n",
    "\n",
    "compareBbc = BalancedBaggingClassifier(base_estimator=clf,\n",
    "                                n_estimators=n_estimators,\n",
    "                                oob_score = True,\n",
    "                                random_state=rand_state,\n",
    "                                sampling_strategy = 'not majority',\n",
    "                               )\n",
    "compareBbc.fit(X_train[:,4096+2707:],y_train)\n",
    "# print(\"Out of Bag Score Compare %f\" % compareBbc.oob_score_)\n",
    "# print(\"Validation split accuracy Compare %f\" % accuracy_score(y_val,compareBbc.predict(X_val[:,4096+2707:])))\n",
    "verboseMetrics(y_val,compareBbc.predict_proba(X_val[:,4096+2707:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Weighted fusion posteriors\n",
    "\n",
    "weights = [.53,.17,.3]\n",
    "\n",
    "softScores = boawBbc.predict_proba(X_train[:,:4096])*weights[1]+fbankBbc.predict_proba(X_train[:,4096:4096+2707])*weights[2]+compareBbc.predict_proba(X_train[:,4096+2707:])*weights[0]\n",
    "print(\"Training accuracy Combination %f\" % accuracy_score(y_train, np.argmax(softScores,axis=-1)))\n",
    "verboseMetrics(y_train,softScores)\n",
    "\n",
    "softScores = boawBbc.predict_proba(X_val[:,:4096])*weights[1]+fbankBbc.predict_proba(X_val[:,4096:4096+2707])*weights[2]+compareBbc.predict_proba(X_val[:,4096+2707:])*weights[0]\n",
    "print(\"Validation accuracy Combination %f\" % accuracy_score(y_val, np.argmax(softScores,axis=-1)))\n",
    "verboseMetrics(y_val,softScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "rand_states = np.random.randint(20000,size=(n_estimators,))\n",
    "\n",
    "results = []\n",
    "softScores = []\n",
    "\n",
    "\n",
    "\n",
    "for idx,rand_state in enumerate(rand_states):\n",
    "    rus = RandomOverSampler(random_state=rand_state)    \n",
    "    X,y = rus.fit_resample(X_train[:,4096+2707:],y_train)\n",
    "    \n",
    "    clf = NuSVC(kernel='linear',probability=True,verbose=False,\n",
    "              random_state=rand_state, nu = .5)\n",
    "    \n",
    "    print(\"Training SVM %d\" % idx)\n",
    "    clf.fit(X,y)\n",
    "    \n",
    "    softScores.append(clf.predict_proba(X_val[:,4096+2707:]))\n",
    "    results.append(verboseMetrics(y_val,softScores[-1]))\n",
    "    \n",
    "    del clf\n",
    "    \n",
    "print(np.mean(results))\n",
    "print(np.std(results))\n",
    "\n",
    "init = np.asarray(np.zeros((342,2)))\n",
    "for each in softScores:\n",
    "    init+=each\n",
    "print(\"Posterior Fusion Score:\")\n",
    "verboseMetrics(y_val,init)\n",
    "\n",
    "sns.distplot(results,20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shapepe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

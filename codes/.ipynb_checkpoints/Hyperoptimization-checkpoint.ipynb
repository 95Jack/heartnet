{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization using hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, absolute_import\n",
    "# import tensorflow as tf\n",
    "# from keras.backend.tensorflow_backend import set_session\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "# set_session(tf.Session(config=config))\n",
    "# from clr_callback import CyclicLR\n",
    "# import dill\n",
    "from AudioDataGenerator import AudioDataGenerator\n",
    "import os\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1)\n",
    "import pandas as pd\n",
    "import tables\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "from keras.layers import Input, Conv1D, MaxPooling1D, Dense, Dropout, Flatten, Activation, AveragePooling1D\n",
    "from keras import initializers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.constraints import max_norm\n",
    "from keras.optimizers import Adam  # Nadam, Adamax\n",
    "from keras.callbacks import TensorBoard, Callback, ReduceLROnPlateau\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, CSVLogger\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "from custom_layers import Conv1D_zerophase_linear, Conv1D_linearphase, Conv1D_zerophase,\\\n",
    "    DCT1D, Conv1D_gammatone, Conv1D_linearphaseType\n",
    "from heartnet_v1 import log_macc, write_meta, compute_weight, reshape_folds, results_log\n",
    "from utils import DenseNet\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.losses import categorical_crossentropy\n",
    "sns.set()\n",
    "import ast # for list import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def branch(input_tensor,num_filt,kernel_size,random_seed,padding,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable):\n",
    "\n",
    "    num_filt1, num_filt2 = num_filt\n",
    "    t = Conv1D(num_filt1, kernel_size=kernel_size,\n",
    "                kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                padding=padding,\n",
    "                use_bias=bias,\n",
    "                kernel_constraint=max_norm(maxnorm),\n",
    "                trainable=trainable,\n",
    "                kernel_regularizer=l2(l2_reg))(input_tensor)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    t = MaxPooling1D(pool_size=subsam)(t)\n",
    "    t = Conv1D(num_filt2, kernel_size=kernel_size,\n",
    "               kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "               padding=padding,\n",
    "               use_bias=bias,\n",
    "               trainable=trainable,\n",
    "               kernel_constraint=max_norm(maxnorm),\n",
    "               kernel_regularizer=l2(l2_reg))(t)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    t = MaxPooling1D(pool_size=subsam)(t)\n",
    "    # t = Flatten()(t)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldname='fold0_noFIR'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values initialized\n"
     ]
    }
   ],
   "source": [
    "random_seed=1\n",
    "batch_size=64\n",
    "fold_dir = '/media/taufiq/Data1/heart_sound/feature/segmented_noFIR/folds_dec_2018/'\n",
    "log_dir= '/media/taufiq/Data/heart_sound/Heart_Sound/codes/logs/'\n",
    "bn_momentum = 0.99\n",
    "eps= 1.1e-5\n",
    "bias=False\n",
    "l2_reg=0.\n",
    "# l2_reg_dense=0.\n",
    "kernel_size=5\n",
    "maxnorm=10000.\n",
    "dropout_rate=0.5\n",
    "dropout_rate_dense=0.\n",
    "padding='valid'\n",
    "activation_function='relu'\n",
    "subsam=2\n",
    "load_path=False\n",
    "lr=0.0012843784 \n",
    "lr_decay=0.0001132885\n",
    "FIR_train=True\n",
    "num_filt=(8,4)\n",
    "num_dense=20\n",
    "params = dict()\n",
    "print(\"values initialized\")\n",
    "\n",
    "model_dir = '/media/taufiq/Data1/heart_sound/models/'\n",
    "fold_dir = '/media/taufiq/Data1/heart_sound/feature/segmented_noFIR/folds_dec_2018/'\n",
    "log_name = foldname + ' ' + str(datetime.now())\n",
    "log_dir = '/media/taufiq/Data1/heart_sound/logs/'\n",
    "if not os.path.exists(model_dir + log_name):\n",
    "    os.makedirs(model_dir + log_name)\n",
    "checkpoint_name = model_dir + log_name + \"/\" + 'weights.{epoch:04d}-{val_acc:.4f}.hdf5'\n",
    "results_path = '/media/taufiq/Data1/heart_sound/results_2class.csv'\n",
    "\n",
    "num_filt = (8, 4)\n",
    "num_dense = 20\n",
    "\n",
    "bn_momentum = 0.99\n",
    "eps = 1.1e-5\n",
    "bias = False\n",
    "l2_reg = 0.04864911065093751\n",
    "l2_reg_dense = 0.\n",
    "kernel_size = 5\n",
    "maxnorm = 10000.\n",
    "dropout_rate = 0.5\n",
    "dropout_rate_dense = 0.\n",
    "padding = 'valid'\n",
    "activation_function = 'relu'\n",
    "subsam = 2\n",
    "FIR_train= True\n",
    "trainable = True\n",
    "decision = 'majority'  # Decision algorithm for inference over total recording ('majority','confidence')\n",
    "\n",
    "# lr =  0.00125 ## After bayesian optimization\n",
    "\n",
    "###### lr_decay optimization ######\n",
    "lr_decay =0.0001132885"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79810\n",
      "6710\n",
      "(79810, 2500, 1)\n",
      "(79810, 1)\n",
      "(6710, 2500, 1)\n",
      "(6710, 1)\n"
     ]
    }
   ],
   "source": [
    "feat = tables.open_file(fold_dir + foldname + '.mat')\n",
    "x_train = feat.root.trainX[:]\n",
    "y_train = feat.root.trainY[0, :]\n",
    "x_val = feat.root.valX[:]\n",
    "y_val = feat.root.valY[0, :]\n",
    "train_parts = feat.root.train_parts[:]\n",
    "val_parts = feat.root.val_parts[0, :]\n",
    "\n",
    "############## Relabeling ################\n",
    "\n",
    "for i in range(0, y_train.shape[0]):\n",
    "    if y_train[i] == -1:\n",
    "        y_train[i] = 0  ## Label 0 for normal 1 for abnormal\n",
    "for i in range(0, y_val.shape[0]):\n",
    "    if y_val[i] == -1:\n",
    "        y_val[i] = 0\n",
    "\n",
    "############# Parse Database names ########\n",
    "\n",
    "train_files = []\n",
    "for each in feat.root.train_files[:][0]:\n",
    "    train_files.append(chr(each))\n",
    "print(len(train_files))\n",
    "val_files = []\n",
    "for each in feat.root.val_files[:][0]:\n",
    "    val_files.append(chr(each))\n",
    "print(len(val_files))\n",
    "\n",
    "################### Reshaping ############\n",
    "\n",
    "x_train, y_train, x_val, y_val = reshape_folds(x_train, x_val, y_train, y_val)\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_val = to_categorical(y_val, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = AudioDataGenerator(shift=.1,\n",
    "                             # roll_range=.1,\n",
    "                             # fill_mode='reflect',\n",
    "                             # featurewise_center=True,\n",
    "                             # zoom_range=.1,\n",
    "                             # zca_whitening=True,\n",
    "                             # samplewise_center=True,\n",
    "                             # samplewise_std_normalization=True,\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heartnet(load_path,activation_function='relu', bn_momentum=0.99,\n",
    "             bias=False, dropout_rate=0.5, dropout_rate_dense=0.0,\n",
    "             eps=1.1e-5, kernel_size=5, l2_reg=0.0, l2_reg_dense=0.0,\n",
    "             lr=0.0012843784, lr_decay=0.0001132885, maxnorm=10000.,\n",
    "             padding='valid', random_seed=1, subsam=2, num_filt=(8, 4),\n",
    "             num_dense=20,FIR_train=False,trainable=True,type_=1,args=1):\n",
    "\n",
    "    input = Input(shape=(2500, 1))\n",
    "\n",
    "    coeff_path = '/media/taufiq/Data1/heart_sound/heartnetTransfer/filterbankcoeff60.mat'\n",
    "    coeff = tables.open_file(coeff_path)\n",
    "    b1 = coeff.root.b1[:]\n",
    "    b1 = np.hstack(b1)\n",
    "    b1 = np.reshape(b1, [b1.shape[0], 1, 1])\n",
    "\n",
    "    b2 = coeff.root.b2[:]\n",
    "    b2 = np.hstack(b2)\n",
    "    b2 = np.reshape(b2, [b2.shape[0], 1, 1])\n",
    "\n",
    "    b3 = coeff.root.b3[:]\n",
    "    b3 = np.hstack(b3)\n",
    "    b3 = np.reshape(b3, [b3.shape[0], 1, 1])\n",
    "\n",
    "    b4 = coeff.root.b4[:]\n",
    "    b4 = np.hstack(b4)\n",
    "    b4 = np.reshape(b4, [b4.shape[0], 1, 1])\n",
    "\n",
    "    ## Conv1D_linearphase\n",
    "\n",
    "    # input1 = Conv1D_linearphase(1 ,61, use_bias=False,\n",
    "    #                 # kernel_initializer=initializers.he_normal(random_seed),\n",
    "    #                 weights=[b1[30:]],\n",
    "    #                 padding='same',trainable=FIR_train)(input)\n",
    "    # input2 = Conv1D_linearphase(1, 61, use_bias=False,\n",
    "    #                 # kernel_initializer=initializers.he_normal(random_seed),\n",
    "    #                 weights=[b2[30:]],\n",
    "    #                 padding='same',trainable=FIR_train)(input)\n",
    "    # input3 = Conv1D_linearphase(1, 61, use_bias=False,\n",
    "    #                 # kernel_initializer=initializers.he_normal(random_seed),\n",
    "    #                 weights=[b3[30:]],\n",
    "    #                 padding='same',trainable=FIR_train)(input)\n",
    "    # input4 = Conv1D_linearphase(1, 61, use_bias=False,\n",
    "    #                 # kernel_initializer=initializers.he_normal(random_seed),\n",
    "    #                 weights=[b4[30:]],\n",
    "    #                 padding='same',trainable=FIR_train)(input)\n",
    "\n",
    "    ## Conv1D_linearphase Anti-Symmetric\n",
    "    #\n",
    "\n",
    "    if type_ % 2:\n",
    "        weight_idx = 30\n",
    "    else:\n",
    "        weight_idx = 31\n",
    "\n",
    "    input1 = Conv1D_linearphaseType(1 ,61, use_bias=False,\n",
    "                    # kernel_initializer=initializers.he_normal(random_seed),\n",
    "                    weights=[b1[weight_idx:]],\n",
    "                    padding='same',trainable=FIR_train, type = type_)(input)\n",
    "    input2 = Conv1D_linearphaseType(1, 61, use_bias=False,\n",
    "                    # kernel_initializer=initializers.he_normal(random_seed),\n",
    "                    weights=[b2[weight_idx:]],\n",
    "                    padding='same',trainable=FIR_train, type = type_)(input)\n",
    "    input3 = Conv1D_linearphaseType(1, 61, use_bias=False,\n",
    "                    # kernel_initializer=initializers.he_normal(random_seed),\n",
    "                    weights=[b3[weight_idx:]],\n",
    "                    padding='same',trainable=FIR_train, type = type_)(input)\n",
    "    input4 = Conv1D_linearphaseType(1, 61, use_bias=False,\n",
    "                    # kernel_initializer=initializers.he_normal(random_seed),\n",
    "                    weights=[b4[weight_idx:]],\n",
    "                    padding='same',trainable=FIR_train, type = type_)(input)\n",
    "\n",
    "    #Conv1D_gammatone\n",
    "\n",
    "    # input1 = Conv1D_gammatone(kernel_size=81,filters=1,fsHz=1000,use_bias=False,padding='same')(input)\n",
    "    # input2 = Conv1D_gammatone(kernel_size=81,filters=1,fsHz=1000,use_bias=False,padding='same')(input)\n",
    "    # input3 = Conv1D_gammatone(kernel_size=81,filters=1,fsHz=1000,use_bias=False,padding='same')(input)\n",
    "    # input4 = Conv1D_gammatone(kernel_size=81,filters=1,fsHz=1000,use_bias=False,padding='same')(input)\n",
    "\n",
    "    t1 = branch(input1,num_filt,kernel_size,random_seed,padding,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "    t2 = branch(input2,num_filt,kernel_size,random_seed,padding,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "    t3 = branch(input3,num_filt,kernel_size,random_seed,padding,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "    t4 = branch(input4,num_filt,kernel_size,random_seed,padding,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "\n",
    "    merged = Concatenate(axis=-1)([t1, t2, t3, t4])\n",
    "    merged = DenseNet(merged,\n",
    "                      depth=int(3*args[0]+4),\n",
    "                      nb_dense_block=args[1],\n",
    "                      growth_rate=int(args[2]),\n",
    "#                       kernel_size=args[3],\n",
    "                      kernel_size=5,\n",
    "#                       nb_filter=args[4],\n",
    "                      nb_filter=16,\n",
    "#                       dropout_rate=args[5],\n",
    "                      dropout_rate=dropout_rate,\n",
    "                     )\n",
    "    # 7,4,4,5,16; 7,1,4,5,16\n",
    "\n",
    "    # merged = DCT1D()(merged)\n",
    "    merged = Flatten()(merged)\n",
    "    merged = Dense(num_dense,\n",
    "                   activation=activation_function,\n",
    "                   kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                   use_bias=bias,\n",
    "                   kernel_constraint=max_norm(maxnorm),\n",
    "                   kernel_regularizer=l2(l2_reg_dense))(merged)\n",
    "    # merged = BatchNormalization(epsilon=eps,momentum=bn_momentum,axis=-1) (merged)\n",
    "    # merged = Activation(activation_function)(merged)\n",
    "    merged = Dropout(rate=dropout_rate_dense, seed=random_seed)(merged)\n",
    "    merged = Dense(2, activation='softmax')(merged)\n",
    "\n",
    "    model = Model(inputs=input, outputs=merged)\n",
    "\n",
    "    if load_path:  # If path for loading model was specified\n",
    "        model.load_weights(filepath=load_path, by_name=False)\n",
    "\n",
    "    adam = Adam(lr=lr, decay=lr_decay)\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(args):\n",
    "    print(\"args {}\".format(args))\n",
    "    \n",
    "    log_name = \"hyperopt-{}\".format(args) + str(datetime.now())\n",
    "    if not os.path.exists(model_dir + log_name):\n",
    "        os.makedirs(model_dir + log_name)\n",
    "    checkpoint_name = model_dir + log_name + \"/\" + 'weights.{epoch:04d}-{val_acc:.4f}.hdf5'\n",
    "    \n",
    "    \n",
    "    csv_logger = CSVLogger(log_dir + log_name + '/training.csv')\n",
    "    tensbd = TensorBoard(log_dir=log_dir + log_name,\n",
    "                            batch_size=batch_size)\n",
    "    modelcheckpnt = ModelCheckpoint(filepath=checkpoint_name,\n",
    "                                monitor='val_acc',\n",
    "                                save_best_only=True, mode='max')\n",
    "    \n",
    "    model = heartnet(load_path,activation_function, bn_momentum, bias, dropout_rate, dropout_rate_dense,\n",
    "                         eps, kernel_size, l2_reg, l2_reg_dense, lr, lr_decay, maxnorm,\n",
    "                         padding, random_seed, subsam, num_filt, num_dense, FIR_train, trainable, 1, args)\n",
    "    model.summary()\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size, shuffle=True,\n",
    "                                     seed=random_seed),\n",
    "                            steps_per_epoch=len(x_train) // batch_size,\n",
    "                            # max_queue_size=20,\n",
    "                            use_multiprocessing=False,\n",
    "                            epochs=20,\n",
    "                            verbose=1,\n",
    "                            shuffle=True,\n",
    "                            callbacks=[modelcheckpnt,\n",
    "                                       log_macc(val_parts, decision=decision,verbose=1, val_files=val_files),\n",
    "                                       tensbd, csv_logger],\n",
    "                            validation_data=(x_val, y_val),\n",
    "                            initial_epoch=0,\n",
    "                            )\n",
    "    y_pred = model.predict(x_val)\n",
    "    loss = K.eval(K.mean(K.variable(K.eval(categorical_crossentropy(K.variable(y_val),K.variable(y_pred))))))\n",
    "    params[str(args)]=loss\n",
    "    print(\"Loss: %d\" % loss)\n",
    "    return loss    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args (18.0, 3, 2.0, 3, 16, 0.6145160414670338)\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/40\n",
      "1247/1247 [==============================] - 150s 120ms/step - loss: 1.0012 - acc: 0.8418 - val_loss: 0.8024 - val_acc: 0.7052\n",
      "6710/6710 [==============================] - 7s 1ms/step\n",
      "TN:86,FP:60,FN:37,TP:101,Macc:0.660462525572,F1:0.675579767161\n",
      "Epoch 2/40\n",
      "1247/1247 [==============================] - 132s 106ms/step - loss: 0.3854 - acc: 0.8622 - val_loss: 0.7301 - val_acc: 0.5770\n",
      "6710/6710 [==============================] - 4s 623us/step\n",
      "TN:42,FP:104,FN:15,TP:123,Macc:0.589487743991,F1:0.673967389163\n",
      "Epoch 3/40\n",
      "1247/1247 [==============================] - 132s 106ms/step - loss: 0.3301 - acc: 0.8717 - val_loss: 0.6698 - val_acc: 0.6759\n",
      "6710/6710 [==============================] - 4s 622us/step\n",
      "TN:76,FP:70,FN:37,TP:101,Macc:0.626215952809,F1:0.65371619908\n",
      "Epoch 4/40\n",
      "1247/1247 [==============================] - 134s 108ms/step - loss: 0.3026 - acc: 0.8792 - val_loss: 0.6510 - val_acc: 0.7086\n",
      "6710/6710 [==============================] - 4s 618us/step\n",
      "TN:77,FP:69,FN:28,TP:110,Macc:0.662249303138,F1:0.694000853031\n",
      "Epoch 5/40\n",
      "1247/1247 [==============================] - 134s 108ms/step - loss: 0.2889 - acc: 0.8852 - val_loss: 0.7136 - val_acc: 0.6152\n",
      "6710/6710 [==============================] - 4s 619us/step\n",
      "TN:49,FP:97,FN:11,TP:127,Macc:0.627953097393,F1:0.701652226375\n",
      "Epoch 6/40\n",
      "1247/1247 [==============================] - 134s 107ms/step - loss: 0.2802 - acc: 0.8873 - val_loss: 0.7049 - val_acc: 0.6185\n",
      "6710/6710 [==============================] - 4s 623us/step\n",
      "TN:48,FP:98,FN:11,TP:127,Macc:0.624528440117,F1:0.699719291465\n",
      "Epoch 7/40\n",
      "1247/1247 [==============================] - 134s 107ms/step - loss: 0.2737 - acc: 0.8883 - val_loss: 0.7088 - val_acc: 0.6255\n",
      "6710/6710 [==============================] - 4s 622us/step\n",
      "TN:46,FP:100,FN:7,TP:131,Macc:0.632171878032,F1:0.710021907338\n",
      "Epoch 8/40\n",
      "1247/1247 [==============================] - 137s 109ms/step - loss: 0.2721 - acc: 0.8910 - val_loss: 0.6682 - val_acc: 0.6475\n",
      "6710/6710 [==============================] - 4s 626us/step\n",
      "TN:61,FP:85,FN:20,TP:118,Macc:0.636440291655,F1:0.692076766666\n",
      "Epoch 9/40\n",
      "1247/1247 [==============================] - 139s 111ms/step - loss: 0.2627 - acc: 0.8934 - val_loss: 0.7173 - val_acc: 0.6219\n",
      "6710/6710 [==============================] - 4s 651us/step\n",
      "TN:47,FP:99,FN:8,TP:130,Macc:0.631973347192,F1:0.708441662207\n",
      "Epoch 10/40\n",
      "1247/1247 [==============================] - 136s 109ms/step - loss: 0.2605 - acc: 0.8933 - val_loss: 0.6862 - val_acc: 0.6471\n",
      "6710/6710 [==============================] - 4s 646us/step\n",
      "TN:60,FP:86,FN:14,TP:124,Macc:0.654754763081,F1:0.712638368582\n",
      "Epoch 11/40\n",
      "1247/1247 [==============================] - 136s 109ms/step - loss: 0.2599 - acc: 0.8932 - val_loss: 0.6364 - val_acc: 0.6775\n",
      "6710/6710 [==============================] - 4s 624us/step\n",
      "TN:68,FP:78,FN:23,TP:115,Macc:0.649543328237,F1:0.694858654051\n",
      "Epoch 12/40\n",
      "1247/1247 [==============================] - 134s 107ms/step - loss: 0.2554 - acc: 0.8959 - val_loss: 0.6838 - val_acc: 0.6511\n",
      "6710/6710 [==============================] - 4s 630us/step\n",
      "TN:53,FP:93,FN:6,TP:132,Macc:0.659767667083,F1:0.72726749916\n",
      "Epoch 13/40\n",
      "1247/1247 [==============================] - 134s 107ms/step - loss: 0.2520 - acc: 0.8967 - val_loss: 0.7274 - val_acc: 0.6218\n",
      "6710/6710 [==============================] - 4s 626us/step\n",
      "TN:47,FP:99,FN:11,TP:127,Macc:0.621103782841,F1:0.697796977124\n",
      "Epoch 14/40\n",
      "1247/1247 [==============================] - 175s 141ms/step - loss: 0.2497 - acc: 0.8980 - val_loss: 0.7089 - val_acc: 0.6314\n",
      "6710/6710 [==============================] - 4s 600us/step\n",
      "TN:55,FP:91,FN:20,TP:118,Macc:0.615892347997,F1:0.680109960957\n",
      "Epoch 15/40\n",
      "1247/1247 [==============================] - 133s 106ms/step - loss: 0.2476 - acc: 0.8988 - val_loss: 0.7547 - val_acc: 0.6130\n",
      "6710/6710 [==============================] - 4s 616us/step\n",
      "TN:47,FP:99,FN:10,TP:128,Macc:0.624726970958,F1:0.701364647784\n",
      "Epoch 16/40\n",
      "1247/1247 [==============================] - 133s 107ms/step - loss: 0.2456 - acc: 0.8988 - val_loss: 0.6934 - val_acc: 0.6542\n",
      "6710/6710 [==============================] - 4s 632us/step\n",
      "TN:54,FP:92,FN:8,TP:130,Macc:0.655945948125,F1:0.722216977568\n",
      "Epoch 17/40\n",
      "1247/1247 [==============================] - 133s 107ms/step - loss: 0.2439 - acc: 0.9003 - val_loss: 0.6985 - val_acc: 0.6499\n",
      "6710/6710 [==============================] - 4s 623us/step\n",
      "TN:52,FP:94,FN:10,TP:128,Macc:0.641850257339,F1:0.711105867137\n",
      "Epoch 18/40\n",
      "1247/1247 [==============================] - 134s 107ms/step - loss: 0.2418 - acc: 0.9007 - val_loss: 0.7233 - val_acc: 0.6480\n",
      "6710/6710 [==============================] - 4s 633us/step\n",
      "TN:55,FP:91,FN:12,TP:126,Macc:0.644877852933,F1:0.709853883347\n",
      "Epoch 19/40\n",
      "1247/1247 [==============================] - 136s 109ms/step - loss: 0.2424 - acc: 0.9004 - val_loss: 0.6616 - val_acc: 0.6744\n",
      "6710/6710 [==============================] - 4s 629us/step\n",
      "TN:64,FP:82,FN:16,TP:122,Macc:0.661207015951,F1:0.713444951375\n",
      "Epoch 20/40\n",
      "1247/1247 [==============================] - 135s 108ms/step - loss: 0.2445 - acc: 0.9000 - val_loss: 0.6762 - val_acc: 0.6715\n",
      "6710/6710 [==============================] - 4s 652us/step\n",
      "TN:73,FP:73,FN:36,TP:102,Macc:0.619565169098,F1:0.651751719589\n",
      "Epoch 21/40\n",
      "1247/1247 [==============================] - 134s 108ms/step - loss: 0.2401 - acc: 0.9012 - val_loss: 0.6541 - val_acc: 0.6793\n",
      "6710/6710 [==============================] - 4s 648us/step\n",
      "TN:62,FP:84,FN:14,TP:124,Macc:0.661604077633,F1:0.716757685361\n",
      "Epoch 22/40\n",
      "1247/1247 [==============================] - 134s 107ms/step - loss: 0.2378 - acc: 0.9018 - val_loss: 0.7154 - val_acc: 0.6544\n",
      "6710/6710 [==============================] - 4s 618us/step\n",
      "TN:56,FP:90,FN:12,TP:126,Macc:0.64830251021,F1:0.711859129599\n",
      "Epoch 23/40\n",
      "1247/1247 [==============================] - 135s 108ms/step - loss: 0.2359 - acc: 0.9024 - val_loss: 0.6956 - val_acc: 0.6605\n",
      "6710/6710 [==============================] - 4s 622us/step\n",
      "TN:57,FP:89,FN:13,TP:125,Macc:0.648103979369,F1:0.710221984769\n",
      "Epoch 24/40\n",
      "1247/1247 [==============================] - 134s 108ms/step - loss: 0.2358 - acc: 0.9025 - val_loss: 0.6746 - val_acc: 0.6735\n",
      "6710/6710 [==============================] - 4s 631us/step\n",
      "TN:64,FP:82,FN:18,TP:120,Macc:0.653960639717,F1:0.705877002185\n",
      "Epoch 25/40\n",
      "1247/1247 [==============================] - 135s 108ms/step - loss: 0.2337 - acc: 0.9034 - val_loss: 0.6745 - val_acc: 0.6981\n",
      "6710/6710 [==============================] - 4s 623us/step\n",
      "TN:100,FP:46,FN:53,TP:85,Macc:0.650436717567,F1:0.63196471231\n",
      "Epoch 26/40\n",
      "1247/1247 [==============================] - 136s 109ms/step - loss: 0.2328 - acc: 0.9028 - val_loss: 0.6526 - val_acc: 0.6946\n",
      "6710/6710 [==============================] - 4s 638us/step\n",
      "TN:91,FP:55,FN:45,TP:93,Macc:0.648600307017,F1:0.650344107093\n",
      "Epoch 27/40\n",
      "1247/1247 [==============================] - 135s 108ms/step - loss: 0.2319 - acc: 0.9037 - val_loss: 0.7006 - val_acc: 0.6626\n",
      "6710/6710 [==============================] - 4s 636us/step\n",
      "TN:61,FP:85,FN:13,TP:125,Macc:0.661802608474,F1:0.718385494655\n",
      "Epoch 28/40\n",
      " 825/1247 [==================>...........] - ETA: 44s - loss: 0.2334 - acc: 0.9027"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-055eeccdc3a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     trials=trials)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         )\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/hyperopt/base.pyc\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             return_argmin=return_argmin)\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     verbose=verbose)\n\u001b[1;32m    319\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/hyperopt/fmin.pyc\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/hyperopt/base.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-67c204f0d25c>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     17\u001b[0m                                        tensbd, csv_logger],\n\u001b[1;32m     18\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                             \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                             )\n\u001b[1;32m     21\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2228\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2229\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2230\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, Trials, fmin, tpe\n",
    "trials = Trials()\n",
    "best = fmin(objective,\n",
    "    space=[hp.quniform('depth',1,30,1),\n",
    "           hp.choice('num_block',[1,2,3]),\n",
    "           hp.quniform('growth',1,20,1),\n",
    "#            hp.choice('kernel_size',[3,5,7]),\n",
    "#            hp.choice('num_filters',[8,16,32]),\n",
    "#            hp.normal('dropout',0.4,0.1)\n",
    "          ],\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=20,\n",
    "    trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "D =(params)\n",
    "\n",
    "plt.bar(range(len(D)), list(D.values()), align='center')\n",
    "plt.xticks(range(len(D)), list(D.keys()),rotation=90)\n",
    "plt.yscale('log',nonposy='clip')\n",
    "# # for python 2.x:\n",
    "# plt.bar(range(len(D)), D.values(), align='center')  # python 2.x\n",
    "# plt.xticks(range(len(D)), D.keys())  # in python 2.x\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

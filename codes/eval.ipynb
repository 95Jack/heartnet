{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function,division,absolute_import\n",
    "import tables\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import model_from_json\n",
    "from custom_layers import Conv1D_linearphase, DCT1D\n",
    "from heartnet_v1 import reshape_folds\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_name = 'fold1+compare 2018-05-05 17:04:36.995687'\n",
    "checkpoint_name = \"/media/taufiq/Data1/heart_sound/models/fold1+compare 2018-05-05 17:04:36.995687/weights.0007-0.8148.hdf5\"\n",
    "min_epoch = 3\n",
    "min_metric = .7\n",
    "foldname = 'fold1+compare'\n",
    "fold_dir = '/media/taufiq/Data1/heart_sound/feature/segmented_noFIR/'\n",
    "model_dir = '/media/taufiq/Data1/heart_sound/models/'\n",
    "log_dir = '/media/taufiq/Data1/heart_sound/logs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = checkpoint_name[:checkpoint_name.find('fold')]\n",
    "log_name = checkpoint_name[checkpoint_name.find('fold'):checkpoint_name.find('weights')-1]\n",
    "print(log_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(model_dir+log_name):\n",
    "    print(\"Model directory found\")\n",
    "    if os.path.isfile(os.path.join(model_dir+log_name,\"model.json\")):\n",
    "        print(\"model.json found. Importing\")\n",
    "    else:\n",
    "        raise ImportError(\"model.json not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(model_dir+log_name,\"model.json\")) as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "model = model_from_json(loaded_model_json,{'Conv1D_linearphase':Conv1D_linearphase,'DCT1D':DCT1D})\n",
    "model.load_weights(checkpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3283\n",
      "515\n",
      "(93942, 2500, 1)\n",
      "(93942, 1)\n",
      "(15511, 2500, 1)\n",
      "(15511, 1)\n"
     ]
    }
   ],
   "source": [
    "############## Importing data ############\n",
    "feat = tables.open_file(fold_dir + foldname + '.mat')\n",
    "x_train = feat.root.trainX[:]\n",
    "y_train = feat.root.trainY[0, :]\n",
    "x_val = feat.root.valX[:]\n",
    "y_val = feat.root.valY[0, :]\n",
    "train_parts = feat.root.train_parts[0, :]\n",
    "val_parts = feat.root.val_parts[0, :]\n",
    "\n",
    "############## Relabeling ################\n",
    "\n",
    "for i in range(0, y_train.shape[0]):\n",
    "    if y_train[i] == -1:\n",
    "        y_train[i] = 0  ## Label 0 for normal 1 for abnormal\n",
    "for i in range(0, y_val.shape[0]):\n",
    "    if y_val[i] == -1:\n",
    "        y_val[i] = 0\n",
    "\n",
    "############# Parse Database names ########\n",
    "\n",
    "train_files = []\n",
    "for each in feat.root.train_files[:][0]:\n",
    "    train_files.append(chr(each))\n",
    "print(len(train_files))\n",
    "val_files = []\n",
    "for each in feat.root.val_files[:][0]:\n",
    "    val_files.append(chr(each))\n",
    "print(len(val_files))\n",
    "\n",
    "################### Reshaping ############\n",
    "\n",
    "x_train, y_train, x_val, y_val = reshape_folds(x_train, x_val, y_train, y_val)\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_val = to_categorical(y_val, num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model from log name\n",
    "\n",
    "\n",
    "Given a log_name it scans through the directories and finds the best three weights considering Sensitivity, Specificity and Macc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory found\n",
      "model.json found. Importing\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 2500, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_linearphase_1 (Conv1D_li (None, 2500, 1)      31          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_linearphase_2 (Conv1D_li (None, 2500, 1)      31          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_linearphase_3 (Conv1D_li (None, 2500, 1)      31          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_linearphase_4 (Conv1D_li (None, 2500, 1)      31          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 2496, 8)      40          conv1d_linearphase_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 2496, 8)      40          conv1d_linearphase_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 2496, 8)      40          conv1d_linearphase_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 2496, 8)      40          conv1d_linearphase_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 2496, 8)      32          conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 2496, 8)      32          conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 2496, 8)      32          conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 2496, 8)      32          conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 2496, 8)      0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 2496, 8)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 2496, 8)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 2496, 8)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2496, 8)      0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 2496, 8)      0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 2496, 8)      0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 2496, 8)      0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1248, 8)      0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 1248, 8)      0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 1248, 8)      0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 1248, 8)      0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1244, 4)      160         max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1244, 4)      160         max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1244, 4)      160         max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 1244, 4)      160         max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1244, 4)      16          conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1244, 4)      16          conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1244, 4)      16          conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1244, 4)      16          conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1244, 4)      0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 1244, 4)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 1244, 4)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 1244, 4)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1244, 4)      0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1244, 4)      0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1244, 4)      0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 1244, 4)      0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 622, 4)       0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 622, 4)       0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 622, 4)       0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 622, 4)       0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 622, 16)      0           max_pooling1d_2[0][0]            \n",
      "                                                                 max_pooling1d_4[0][0]            \n",
      "                                                                 max_pooling1d_6[0][0]            \n",
      "                                                                 max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dc_t1d_1 (DCT1D)                (None, 622, 16)      0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 9952)         0           dc_t1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 20)           199040      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 20)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            42          dropout_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 200,198\n",
      "Trainable params: 199,978\n",
      "Non-trainable params: 220\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir(model_dir+log_name):\n",
    "    print(\"Model directory found\")\n",
    "    if os.path.isfile(os.path.join(model_dir+log_name,\"model.json\")):\n",
    "        print(\"model.json found. Importing\")\n",
    "    else:\n",
    "        raise ImportError(\"model.json not found\")\n",
    "\n",
    "with open(os.path.join(model_dir+log_name,\"model.json\")) as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "model = model_from_json(loaded_model_json,{'Conv1D_linearphase':Conv1D_linearphase,'DCT1D':DCT1D})\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_csv = os.path.join(log_dir+log_name,\"training.csv\")\n",
    "df = pd.read_csv(training_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens_idx = df['val_sensitivity'][df.epoch>min_epoch][df.val_specificity>min_metric].idxmax()\n",
    "spec_idx = df['val_specificity'][df.epoch>min_epoch][df.val_sensitivity>min_metric].idxmax()\n",
    "macc_idx = df['val_macc'][df.epoch>min_epoch].idxmax()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Sensitivity model: \tweights.0007-0.8059.hdf5\n",
      "Best Specificity model: \tweights.0005-0.7794.hdf5\n",
      "Best Macc model: \t\tweights.0007-0.8059.hdf5\n"
     ]
    }
   ],
   "source": [
    "weights = dict()\n",
    "weights['sens_weight'] = \"weights.%.4d-%.4f.hdf5\" % (df.epoch.iloc[sens_idx],df.val_acc.iloc[sens_idx])\n",
    "weights['spec_weight'] = \"weights.%.4d-%.4f.hdf5\" % (df.epoch.iloc[spec_idx],df.val_acc.iloc[spec_idx])\n",
    "weights['macc_weight'] = \"weights.%.4d-%.4f.hdf5\" % (df.epoch.iloc[macc_idx],df.val_acc.iloc[macc_idx])\n",
    "print(\"Best Sensitivity model: \\t{}\".format(weights['sens_weight']))\n",
    "print(\"Best Specificity model: \\t{}\".format(weights['spec_weight']))\n",
    "print(\"Best Macc model: \\t\\t{}\".format(weights['macc_weight']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training and Validation Filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filenames Loaded : Train files 3283 and Validation Files 515\n"
     ]
    }
   ],
   "source": [
    "import matlab.engine\n",
    "eng = matlab.engine.start_matlab()\n",
    "fold1_filenames = eng.load(os.path.join(fold_dir,'fold1_filenames.mat'))\n",
    "compare_filenames = eng.load(os.path.join(fold_dir,'compare_filenames.mat'))\n",
    "eng.quit()\n",
    "\n",
    "train_filenames = fold1_filenames['train_files']\n",
    "train_filenames.extend(compare_filenames['train_files'])\n",
    "val_filenames = fold1_filenames['val_files']\n",
    "val_filenames.extend(compare_filenames['val_files'])\n",
    "print(\"Filenames Loaded : Train files {} and Validation Files {}\".format(len(train_filenames),len(val_filenames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenames</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a0156.wav</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a0148.wav</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a0099.wav</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b0265.wav</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b0319.wav</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   filenames dataset\n",
       "0  a0156.wav       a\n",
       "1  a0148.wav       a\n",
       "2  a0099.wav       a\n",
       "3  b0265.wav       b\n",
       "4  b0319.wav       b"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain = pd.DataFrame(train_filenames,columns={\"filenames\"})\n",
    "dfVal = pd.DataFrame(val_filenames,columns={\"filenames\"})\n",
    "dfTrain['dataset'] = train_files\n",
    "dfVal['dataset'] = val_files\n",
    "dfVal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get true labels per recording and append "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-8260148e2b50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_parts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m## for e00032 in validation0 there was no cardiac cycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# ~ print \"part {} start {} stop {}\".format(s,start_idx,start_idx+int(s)-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "true = []\n",
    "start_idx = 0\n",
    "y_val_rec = np.transpose(np.argmax(y_val, axis=-1))\n",
    "for s in val_parts:\n",
    "\n",
    "    if not s:  ## for e00032 in validation0 there was no cardiac cycle\n",
    "        continue\n",
    "    # ~ print \"part {} start {} stop {}\".format(s,start_idx,start_idx+int(s)-1)\n",
    "\n",
    "    temp_ = y_val_rec[start_idx:start_idx + int(s) - 1]\n",
    "\n",
    "    if (sum(temp_ == 0) > sum(temp_ == 1)):\n",
    "        true.append(0)\n",
    "    else:\n",
    "        true.append(1)\n",
    "\n",
    "    start_idx = start_idx + int(s)\n",
    "dfVal['true'] = true\n",
    "\n",
    "\n",
    "true = []\n",
    "\n",
    "start_idx = 0\n",
    "\n",
    "y_val_rec = np.transpose(np.argmax(y_train, axis=-1))\n",
    "\n",
    "for s in train_parts:\n",
    "\n",
    "    if not s:  ## for e00032 in validation0 there was no cardiac cycle\n",
    "        continue\n",
    "    # ~ print \"part {} start {} stop {}\".format(s,start_idx,start_idx+int(s)-1)\n",
    "\n",
    "    temp_ = y_val_rec[start_idx:start_idx + int(s) - 1]\n",
    "\n",
    "    if (sum(temp_ == 0) > sum(temp_ == 1)):\n",
    "        true.append(0)\n",
    "    else:\n",
    "        true.append(1)\n",
    "\n",
    "    start_idx = start_idx + int(s)\n",
    "dfTrain['true'] = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36., 26., 25., ..., 34., 33., 32.])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_parts[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15511/15511 [==============================] - 2s 115us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6221047 , 0.3778953 ],\n",
       "       [0.6336504 , 0.3663496 ],\n",
       "       [0.64863044, 0.3513696 ],\n",
       "       ...,\n",
       "       [0.8927339 , 0.1072661 ],\n",
       "       [0.94397974, 0.05602031],\n",
       "       [0.9821339 , 0.01786613]], dtype=float32)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_val, verbose=1)\n",
    "y_pred_hard = np.argmax(y_pred,axis=-1)\n",
    "pred = []\n",
    "start_idx = 0\n",
    "y_val_rec = np.transpose(np.argmax(y_val, axis=-1))\n",
    "for s in val_parts:\n",
    "\n",
    "    if not s:  ## for e00032 in validation0 there was no cardiac cycle\n",
    "        continue\n",
    "    # ~ print \"part {} start {} stop {}\".format(s,start_idx,start_idx+int(s)-1)\n",
    "\n",
    "    temp_ = y_val_rec[start_idx:start_idx + int(s) - 1]\n",
    "\n",
    "    if (sum(temp_ == 0) > sum(temp_ == 1)):\n",
    "        true.append(0)\n",
    "    else:\n",
    "        true.append(1)\n",
    "\n",
    "    start_idx = start_idx + int(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_soft = np.asarray([y_pred[i,j] for i,j in zip(range(len(y_pred)),np.nditer(y_pred_hard))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".6+.3+.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function,division,absolute_import\n",
    "import tables\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import model_from_json\n",
    "from custom_layers import Conv1D_linearphase, DCT1D\n",
    "from heartnet_v1 import reshape_folds\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = \"/media/taufiq/Data1/heart_sound/models/fold1+compare 2018-05-05 17:04:36.995687/weights.0007-0.8148.hdf5\"\n",
    "foldname = 'fold1+compare'\n",
    "fold_dir = '/media/taufiq/Data1/heart_sound/feature/segmented_noFIR/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold1+compare 2018-05-05 17:04:36.995687\n"
     ]
    }
   ],
   "source": [
    "model_dir = checkpoint_name[:checkpoint_name.find('fold')]\n",
    "log_name = checkpoint_name[checkpoint_name.find('fold'):checkpoint_name.find('weights')-1]\n",
    "print(log_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory found\n",
      "model.json found. Importing\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir(model_dir+log_name):\n",
    "    print(\"Model directory found\")\n",
    "    if os.path.isfile(os.path.join(model_dir+log_name,\"model.json\")):\n",
    "        print(\"model.json found. Importing\")\n",
    "    else:\n",
    "        raise ImportError(\"model.json not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_dir+log_name+\"/model.json\") as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "model = model_from_json(loaded_model_json,{'Conv1D_linearphase':Conv1D_linearphase,'DCT1D':DCT1D})\n",
    "model.load_weights(checkpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3283\n",
      "515\n",
      "(93942, 2500, 1)\n",
      "(93942, 1)\n",
      "(15511, 2500, 1)\n",
      "(15511, 1)\n"
     ]
    }
   ],
   "source": [
    "############## Importing data ############\n",
    "feat = tables.open_file(fold_dir + foldname + '.mat')\n",
    "x_train = feat.root.trainX[:]\n",
    "y_train = feat.root.trainY[0, :]\n",
    "x_val = feat.root.valX[:]\n",
    "y_val = feat.root.valY[0, :]\n",
    "train_parts = feat.root.train_parts[:]\n",
    "val_parts = feat.root.val_parts[0, :]\n",
    "\n",
    "############## Relabeling ################\n",
    "\n",
    "for i in range(0, y_train.shape[0]):\n",
    "    if y_train[i] == -1:\n",
    "        y_train[i] = 0  ## Label 0 for normal 1 for abnormal\n",
    "for i in range(0, y_val.shape[0]):\n",
    "    if y_val[i] == -1:\n",
    "        y_val[i] = 0\n",
    "\n",
    "############# Parse Database names ########\n",
    "\n",
    "train_files = []\n",
    "for each in feat.root.train_files[:][0]:\n",
    "    train_files.append(chr(each))\n",
    "print(len(train_files))\n",
    "val_files = []\n",
    "for each in feat.root.val_files[:][0]:\n",
    "    val_files.append(chr(each))\n",
    "print(len(val_files))\n",
    "\n",
    "################### Reshaping ############\n",
    "\n",
    "x_train, y_train, x_val, y_val = reshape_folds(x_train, x_val, y_train, y_val)\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_val = to_categorical(y_val, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3389.0\n",
      "312.0\n",
      "403.0\n",
      "186.0\n",
      "4657.0\n",
      "692.0\n",
      "5872.0\n"
     ]
    }
   ],
   "source": [
    "for dataset in ['a','b','c','d','e','f','x']:\n",
    "    mask = np.asarray(val_files) == dataset\n",
    "    temp = np.asarray(val_parts)\n",
    "    print(np.sum(temp[mask]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
